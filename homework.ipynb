{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d524ad8f-d024-4ba3-8bbc-2435ec3d0dba",
    "_uuid": "7bb30a6f2a18be45a491092a6e2dfcdcce71a2a0"
   },
   "source": [
    "## Preface\n",
    "This notebooks aims to build a light-weight CNN.\n",
    "It uses specgrams of resampled wav files(rate 8000) as inputs.\n",
    "\n",
    "## File Structure\n",
    "This script assumes data are stored in following strcuture:\n",
    "speech\n",
    "├── test            \n",
    "│   └── audio #test wavfiles\n",
    "├── train           \n",
    "│   ├── audio #train wavfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "_cell_guid": "f7fd8bcb-4451-4d47-bfe8-491c94b3b4eb",
    "_uuid": "712710f20b00f97271136cfeab9937a4c6a2458b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import keras\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "from scipy.io import wavfile\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fb35a2f1-9301-4693-a9ef-9d180b630f05",
    "_uuid": "4b1ba61998e14e15c822c605dbe5961bfed36014"
   },
   "source": [
    "The original sample rate is 16000, and we will resample it to 8000 to reduce data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "_cell_guid": "dc66e1df-f1eb-4df4-ba1a-65b9f1675953",
    "_uuid": "4cc586519523b28d1d595716d8709ace9f27ac9c"
   },
   "outputs": [],
   "source": [
    "L = 16000\n",
    "legal_labels = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "\n",
    "root_path = r'.'\n",
    "out_path = r'.'\n",
    "model_path = r'.'\n",
    "train_data_path = os.path.join(root_path, 'data', 'train', 'audio')\n",
    "test_data_path = os.path.join(root_path, 'data', 'test', 'audio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e53561e4-1c98-44c0-9245-d87f7957faa5",
    "_uuid": "d9a08781f22e574bb1eb0dc29adeb8dddebc8b51"
   },
   "source": [
    "Here are custom_fft and log_specgram functions written by __DavidS__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "_cell_guid": "0fd0b579-8b6f-4253-bf3a-7f75115a42d6",
    "_uuid": "e7ea2c277b6459e532721452ec3cd80d585eae1e"
   },
   "outputs": [],
   "source": [
    "def custom_fft(y, fs):\n",
    "    T = 1.0 / fs\n",
    "    N = y.shape[0]\n",
    "    yf = fft(y)\n",
    "    xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    # FFT is simmetrical, so we take just the first half\n",
    "    # FFT is also complex, to we take just the real part (abs)\n",
    "    vals = 2.0/N * np.abs(yf[0:N//2])\n",
    "    return xf, vals\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c54cda36-777e-4129-bac1-af2d1ed2706e",
    "_uuid": "5a04e71fe7e66e1a31835feebdfef4c63920faf8"
   },
   "source": [
    "Following is the utility function to grab all wav files inside train data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "_cell_guid": "956f3150-544d-46ed-b0ec-da1c1fb142b4",
    "_uuid": "964d71a229e9d4560b9118fa1c80804ebf8d6be8"
   },
   "outputs": [],
   "source": [
    "def list_wavs_fname(dirpath, ext='wav'):\n",
    "    print(dirpath)\n",
    "    fpaths = glob(os.path.join(dirpath, r'*/*' + ext))\n",
    "    pat = r'.+\\\\(\\w+)\\\\\\w+\\.' + ext + '$'\n",
    "    labels = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            labels.append(r.group(1))\n",
    "    pat = r'.+\\\\(\\w+\\.' + ext + ')$'\n",
    "    fnames = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            fnames.append(r.group(1))\n",
    "    return labels, fnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "41025a55-8497-43cf-b316-003af7d9d19f",
    "_uuid": "fc18e87793888952e81a867dd95b1dcc455f9932"
   },
   "source": [
    "__pad_audio__ will pad audios that are less than 16000(1 second) with 0s to make them all have the same length.\n",
    "\n",
    "__chop_audio__ will chop audios that are larger than 16000(eg. wav files in background noises folder) to 16000 in length. In addition, it will create several chunks out of one large wav files given the parameter 'num'.\n",
    "\n",
    "__label_transform__ transform labels into dummies values. It's used in combination with softmax to predict the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "_cell_guid": "200c34a1-851a-4447-9ff7-b4e541f090c6",
    "_uuid": "94e40aef3899acfd3ed85557caa66fee5dd47db2"
   },
   "outputs": [],
   "source": [
    "def pad_audio(samples):\n",
    "    if len(samples) >= L: return samples\n",
    "    else: return np.pad(samples, pad_width=(L - len(samples), 0), mode='constant', constant_values=(0, 0))\n",
    "\n",
    "def chop_audio(samples, L=16000, num=20):\n",
    "    for i in range(num):\n",
    "        beg = np.random.randint(0, len(samples) - L)\n",
    "        yield samples[beg: beg + L]\n",
    "\n",
    "def label_transform(labels):\n",
    "    nlabels = []\n",
    "    for label in labels:\n",
    "        if label == '_background_noise_':\n",
    "            nlabels.append('silence')\n",
    "        elif label not in legal_labels:\n",
    "            nlabels.append('unknown')\n",
    "        else:\n",
    "            nlabels.append(label)\n",
    "    return pd.get_dummies(pd.Series(nlabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dae2a45a-f7ab-4e84-bc73-688eda6eca8e",
    "_uuid": "267314ef41c459c8b6ab903d721980fdd62b4106"
   },
   "source": [
    "Next, we use functions declared above to generate x_train and y_train.\n",
    "label_index is the index used by pandas to create dummy values, we need to save it for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "_cell_guid": "4c8d9fdf-ea3e-45fa-b7ef-52542c70b9db",
    "_uuid": "81bc9722dfb036c73721ae44829d429489662e75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data\\train\\audio\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\scipy\\io\\wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3380"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, fnames = list_wavs_fname(train_data_path)\n",
    "\n",
    "new_sample_rate = 8000\n",
    "y_train = []\n",
    "x_train = []\n",
    "\n",
    "current = 0\n",
    "for label, fname in zip(labels, fnames):\n",
    "    sample_rate, samples = wavfile.read(os.path.join(train_data_path, label, fname))\n",
    "    samples = pad_audio(samples)\n",
    "    if len(samples) > 16000:\n",
    "        n_samples = chop_audio(samples)\n",
    "    else: n_samples = [samples]\n",
    "    for samples in n_samples:\n",
    "        resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        y_train.append(label)\n",
    "        x_train.append(specgram)\n",
    "    current += 1\n",
    "    if current % 1000 == 0:\n",
    "        print(current)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_train = x_train.reshape(tuple(list(x_train.shape) + [1]))\n",
    "y_train = label_transform(y_train)\n",
    "label_index = y_train.columns.values\n",
    "y_train = y_train.values\n",
    "y_train = np.array(y_train)\n",
    "del labels, fnames\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, nclass):\n",
    "        super(CNN, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(1)\n",
    "        self.conv1 = nn.Conv2d(1, 8, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 8, 2)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.conv3 = nn.Conv2d(8, 16, 3)\n",
    "        self.conv4 = nn.Conv2d(16, 16, 3)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "        self.conv5 = nn.Conv2d(16, 32, 3)\n",
    "        self.drop3 = nn.Dropout(p=0.2)\n",
    "        self.fc1 = nn.Linear(2240, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, nclass)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
    "        x = self.drop2(x)\n",
    "        x = F.max_pool2d(F.relu(self.conv5(x)), 2)\n",
    "        x = self.drop3(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.bn3(x)\n",
    "        x = F.softmax(self.fc3(x))        \n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv2): Conv2d(8, 8, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (drop1): Dropout(p=0.2)\n",
      "  (conv3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (drop2): Dropout(p=0.2)\n",
      "  (conv5): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (drop3): Dropout(p=0.2)\n",
      "  (fc1): Linear(in_features=2240, out_features=128, bias=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (fc3): Linear(in_features=128, out_features=12, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Iter [100/3647] Loss: 2.3632\n",
      "Epoch [1/5], Iter [200/3647] Loss: 1.9987\n",
      "Epoch [1/5], Iter [300/3647] Loss: 1.9348\n",
      "Epoch [1/5], Iter [400/3647] Loss: 2.0570\n",
      "Epoch [1/5], Iter [500/3647] Loss: 1.9319\n",
      "Epoch [1/5], Iter [600/3647] Loss: 1.8069\n",
      "Epoch [1/5], Iter [700/3647] Loss: 2.1813\n",
      "Epoch [1/5], Iter [800/3647] Loss: 1.8066\n",
      "Epoch [1/5], Iter [900/3647] Loss: 1.9939\n",
      "Epoch [1/5], Iter [1000/3647] Loss: 1.8689\n",
      "Epoch [1/5], Iter [1100/3647] Loss: 2.1188\n",
      "Epoch [1/5], Iter [1200/3647] Loss: 2.0563\n",
      "Epoch [1/5], Iter [1300/3647] Loss: 1.9938\n",
      "Epoch [1/5], Iter [1400/3647] Loss: 1.9313\n",
      "Epoch [1/5], Iter [1500/3647] Loss: 1.7438\n",
      "Epoch [1/5], Iter [1600/3647] Loss: 2.0563\n",
      "Epoch [1/5], Iter [1700/3647] Loss: 2.0563\n",
      "Epoch [1/5], Iter [1800/3647] Loss: 2.0563\n",
      "Epoch [1/5], Iter [1900/3647] Loss: 1.8688\n",
      "Epoch [1/5], Iter [2000/3647] Loss: 1.8063\n",
      "Epoch [1/5], Iter [2100/3647] Loss: 2.0563\n",
      "Epoch [1/5], Iter [2200/3647] Loss: 2.0563\n",
      "Epoch [1/5], Iter [2300/3647] Loss: 1.8688\n",
      "Epoch [1/5], Iter [2400/3647] Loss: 1.9938\n",
      "Epoch [1/5], Iter [2500/3647] Loss: 2.0563\n",
      "Epoch [1/5], Iter [2600/3647] Loss: 1.8063\n",
      "Epoch [1/5], Iter [2700/3647] Loss: 1.7438\n",
      "Epoch [1/5], Iter [2800/3647] Loss: 1.9313\n",
      "Epoch [1/5], Iter [2900/3647] Loss: 1.9312\n",
      "Epoch [1/5], Iter [3000/3647] Loss: 2.1187\n",
      "Epoch [1/5], Iter [3100/3647] Loss: 1.9937\n",
      "Epoch [1/5], Iter [3200/3647] Loss: 1.9312\n",
      "Epoch [1/5], Iter [3300/3647] Loss: 1.9312\n",
      "Epoch [1/5], Iter [3400/3647] Loss: 1.8687\n",
      "Epoch [1/5], Iter [3500/3647] Loss: 2.2437\n",
      "Epoch [1/5], Iter [3600/3647] Loss: 1.9312\n",
      "Epoch [2/5], Iter [100/3647] Loss: 2.1187\n",
      "Epoch [2/5], Iter [200/3647] Loss: 1.9312\n",
      "Epoch [2/5], Iter [300/3647] Loss: 1.9312\n",
      "Epoch [2/5], Iter [400/3647] Loss: 2.0562\n",
      "Epoch [2/5], Iter [500/3647] Loss: 1.9312\n",
      "Epoch [2/5], Iter [600/3647] Loss: 1.8062\n",
      "Epoch [2/5], Iter [700/3647] Loss: 2.1812\n",
      "Epoch [2/5], Iter [800/3647] Loss: 1.8062\n",
      "Epoch [2/5], Iter [900/3647] Loss: 1.9937\n",
      "Epoch [2/5], Iter [1000/3647] Loss: 1.8687\n",
      "Epoch [2/5], Iter [1100/3647] Loss: 2.1187\n",
      "Epoch [2/5], Iter [1200/3647] Loss: 2.0562\n",
      "Epoch [2/5], Iter [1300/3647] Loss: 1.9937\n",
      "Epoch [2/5], Iter [1400/3647] Loss: 1.9312\n",
      "Epoch [2/5], Iter [1500/3647] Loss: 1.7437\n",
      "Epoch [2/5], Iter [1600/3647] Loss: 2.0562\n",
      "Epoch [2/5], Iter [1700/3647] Loss: 2.0562\n",
      "Epoch [2/5], Iter [1800/3647] Loss: 2.0562\n",
      "Epoch [2/5], Iter [1900/3647] Loss: 1.8687\n",
      "Epoch [2/5], Iter [2000/3647] Loss: 1.8062\n",
      "Epoch [2/5], Iter [2100/3647] Loss: 2.0562\n",
      "Epoch [2/5], Iter [2200/3647] Loss: 2.0562\n",
      "Epoch [2/5], Iter [2300/3647] Loss: 1.8687\n",
      "Epoch [2/5], Iter [2400/3647] Loss: 1.9937\n",
      "Epoch [2/5], Iter [2500/3647] Loss: 2.0562\n",
      "Epoch [2/5], Iter [2600/3647] Loss: 1.8062\n",
      "Epoch [2/5], Iter [2700/3647] Loss: 1.7437\n",
      "Epoch [2/5], Iter [2800/3647] Loss: 1.9312\n",
      "Epoch [2/5], Iter [2900/3647] Loss: 1.9312\n",
      "Epoch [2/5], Iter [3000/3647] Loss: 2.1187\n",
      "Epoch [2/5], Iter [3100/3647] Loss: 1.9937\n",
      "Epoch [2/5], Iter [3200/3647] Loss: 1.9312\n",
      "Epoch [2/5], Iter [3300/3647] Loss: 1.9312\n",
      "Epoch [2/5], Iter [3400/3647] Loss: 1.8687\n",
      "Epoch [2/5], Iter [3500/3647] Loss: 2.2437\n",
      "Epoch [2/5], Iter [3600/3647] Loss: 1.9312\n",
      "Epoch [3/5], Iter [100/3647] Loss: 2.1187\n",
      "Epoch [3/5], Iter [200/3647] Loss: 1.9312\n",
      "Epoch [3/5], Iter [300/3647] Loss: 1.9312\n",
      "Epoch [3/5], Iter [400/3647] Loss: 2.0562\n",
      "Epoch [3/5], Iter [500/3647] Loss: 1.9312\n",
      "Epoch [3/5], Iter [600/3647] Loss: 1.8062\n",
      "Epoch [3/5], Iter [700/3647] Loss: 2.1812\n",
      "Epoch [3/5], Iter [800/3647] Loss: 1.8062\n",
      "Epoch [3/5], Iter [900/3647] Loss: 1.9937\n",
      "Epoch [3/5], Iter [1000/3647] Loss: 1.8687\n",
      "Epoch [3/5], Iter [1100/3647] Loss: 2.1187\n",
      "Epoch [3/5], Iter [1200/3647] Loss: 2.0562\n",
      "Epoch [3/5], Iter [1300/3647] Loss: 1.9937\n",
      "Epoch [3/5], Iter [1400/3647] Loss: 1.9312\n",
      "Epoch [3/5], Iter [1500/3647] Loss: 1.7437\n",
      "Epoch [3/5], Iter [1600/3647] Loss: 2.0562\n",
      "Epoch [3/5], Iter [1700/3647] Loss: 2.0562\n",
      "Epoch [3/5], Iter [1800/3647] Loss: 2.0562\n",
      "Epoch [3/5], Iter [1900/3647] Loss: 1.8687\n",
      "Epoch [3/5], Iter [2000/3647] Loss: 1.8062\n",
      "Epoch [3/5], Iter [2100/3647] Loss: 2.0562\n",
      "Epoch [3/5], Iter [2200/3647] Loss: 2.0562\n",
      "Epoch [3/5], Iter [2300/3647] Loss: 1.8687\n",
      "Epoch [3/5], Iter [2400/3647] Loss: 1.9937\n",
      "Epoch [3/5], Iter [2500/3647] Loss: 2.0562\n",
      "Epoch [3/5], Iter [2600/3647] Loss: 1.8062\n",
      "Epoch [3/5], Iter [2700/3647] Loss: 1.7437\n",
      "Epoch [3/5], Iter [2800/3647] Loss: 1.9312\n",
      "Epoch [3/5], Iter [2900/3647] Loss: 1.9312\n",
      "Epoch [3/5], Iter [3000/3647] Loss: 2.1187\n",
      "Epoch [3/5], Iter [3100/3647] Loss: 1.9937\n",
      "Epoch [3/5], Iter [3200/3647] Loss: 1.9312\n",
      "Epoch [3/5], Iter [3300/3647] Loss: 1.9312\n",
      "Epoch [3/5], Iter [3400/3647] Loss: 1.8687\n",
      "Epoch [3/5], Iter [3500/3647] Loss: 2.2437\n",
      "Epoch [3/5], Iter [3600/3647] Loss: 1.9312\n",
      "Epoch [4/5], Iter [100/3647] Loss: 2.1187\n",
      "Epoch [4/5], Iter [200/3647] Loss: 1.9312\n",
      "Epoch [4/5], Iter [300/3647] Loss: 1.9312\n",
      "Epoch [4/5], Iter [400/3647] Loss: 2.0562\n",
      "Epoch [4/5], Iter [500/3647] Loss: 1.9312\n",
      "Epoch [4/5], Iter [600/3647] Loss: 1.8062\n",
      "Epoch [4/5], Iter [700/3647] Loss: 2.1812\n",
      "Epoch [4/5], Iter [800/3647] Loss: 1.8062\n",
      "Epoch [4/5], Iter [900/3647] Loss: 1.9937\n",
      "Epoch [4/5], Iter [1000/3647] Loss: 1.8687\n",
      "Epoch [4/5], Iter [1100/3647] Loss: 2.1187\n",
      "Epoch [4/5], Iter [1200/3647] Loss: 2.0562\n",
      "Epoch [4/5], Iter [1300/3647] Loss: 1.9937\n",
      "Epoch [4/5], Iter [1400/3647] Loss: 1.9312\n",
      "Epoch [4/5], Iter [1500/3647] Loss: 1.7437\n",
      "Epoch [4/5], Iter [1600/3647] Loss: 2.0562\n",
      "Epoch [4/5], Iter [1700/3647] Loss: 2.0562\n",
      "Epoch [4/5], Iter [1800/3647] Loss: 2.0562\n",
      "Epoch [4/5], Iter [1900/3647] Loss: 1.8687\n",
      "Epoch [4/5], Iter [2000/3647] Loss: 1.8062\n",
      "Epoch [4/5], Iter [2100/3647] Loss: 2.0562\n",
      "Epoch [4/5], Iter [2200/3647] Loss: 2.0562\n",
      "Epoch [4/5], Iter [2300/3647] Loss: 1.8687\n",
      "Epoch [4/5], Iter [2400/3647] Loss: 1.9937\n",
      "Epoch [4/5], Iter [2500/3647] Loss: 2.0562\n",
      "Epoch [4/5], Iter [2600/3647] Loss: 1.8062\n",
      "Epoch [4/5], Iter [2700/3647] Loss: 1.7437\n",
      "Epoch [4/5], Iter [2800/3647] Loss: 1.9312\n",
      "Epoch [4/5], Iter [2900/3647] Loss: 1.9312\n",
      "Epoch [4/5], Iter [3000/3647] Loss: 2.1187\n",
      "Epoch [4/5], Iter [3100/3647] Loss: 1.9937\n",
      "Epoch [4/5], Iter [3200/3647] Loss: 1.9312\n",
      "Epoch [4/5], Iter [3300/3647] Loss: 1.9312\n",
      "Epoch [4/5], Iter [3400/3647] Loss: 1.8687\n",
      "Epoch [4/5], Iter [3500/3647] Loss: 2.2437\n",
      "Epoch [4/5], Iter [3600/3647] Loss: 1.9312\n",
      "Epoch [5/5], Iter [100/3647] Loss: 2.1187\n",
      "Epoch [5/5], Iter [200/3647] Loss: 1.9312\n",
      "Epoch [5/5], Iter [300/3647] Loss: 1.9312\n",
      "Epoch [5/5], Iter [400/3647] Loss: 2.0562\n",
      "Epoch [5/5], Iter [500/3647] Loss: 1.9312\n",
      "Epoch [5/5], Iter [600/3647] Loss: 1.8062\n",
      "Epoch [5/5], Iter [700/3647] Loss: 2.1812\n",
      "Epoch [5/5], Iter [800/3647] Loss: 1.8062\n",
      "Epoch [5/5], Iter [900/3647] Loss: 1.9937\n",
      "Epoch [5/5], Iter [1000/3647] Loss: 1.8687\n",
      "Epoch [5/5], Iter [1100/3647] Loss: 2.1187\n",
      "Epoch [5/5], Iter [1200/3647] Loss: 2.0562\n",
      "Epoch [5/5], Iter [1300/3647] Loss: 1.9937\n",
      "Epoch [5/5], Iter [1400/3647] Loss: 1.9312\n",
      "Epoch [5/5], Iter [1500/3647] Loss: 1.7437\n",
      "Epoch [5/5], Iter [1600/3647] Loss: 2.0562\n",
      "Epoch [5/5], Iter [1700/3647] Loss: 2.0562\n",
      "Epoch [5/5], Iter [1800/3647] Loss: 2.0562\n",
      "Epoch [5/5], Iter [1900/3647] Loss: 1.8687\n",
      "Epoch [5/5], Iter [2000/3647] Loss: 1.8062\n",
      "Epoch [5/5], Iter [2100/3647] Loss: 2.0562\n",
      "Epoch [5/5], Iter [2200/3647] Loss: 2.0562\n",
      "Epoch [5/5], Iter [2300/3647] Loss: 1.8687\n",
      "Epoch [5/5], Iter [2400/3647] Loss: 1.9937\n",
      "Epoch [5/5], Iter [2500/3647] Loss: 2.0562\n",
      "Epoch [5/5], Iter [2600/3647] Loss: 1.8062\n",
      "Epoch [5/5], Iter [2700/3647] Loss: 1.7437\n",
      "Epoch [5/5], Iter [2800/3647] Loss: 1.9312\n",
      "Epoch [5/5], Iter [2900/3647] Loss: 1.9312\n",
      "Epoch [5/5], Iter [3000/3647] Loss: 2.1187\n",
      "Epoch [5/5], Iter [3100/3647] Loss: 1.9937\n",
      "Epoch [5/5], Iter [3200/3647] Loss: 1.9312\n",
      "Epoch [5/5], Iter [3300/3647] Loss: 1.9312\n",
      "Epoch [5/5], Iter [3400/3647] Loss: 1.8687\n",
      "Epoch [5/5], Iter [3500/3647] Loss: 2.2437\n",
      "Epoch [5/5], Iter [3600/3647] Loss: 1.9312\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "nclass = 12\n",
    "batch_size = 16\n",
    "\n",
    "cnn = CNN(nclass)\n",
    "print(cnn)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(len(y_train) // batch_size):\n",
    "        start = i * batch_size\n",
    "        x = Variable(torch.from_numpy(x_train[start : start + batch_size]).permute(0, 3, 1, 2))\n",
    "        y = Variable(torch.from_numpy(np.argmax(y_train[start : start + batch_size], axis=1)))\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                   %(epoch + 1, num_epochs, i + 1, len(y_train) // batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model: 63 %\n"
     ]
    }
   ],
   "source": [
    "cnn.eval() \n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(y_valid) // batch_size):\n",
    "    start = i * batch_size\n",
    "    x = Variable(torch.from_numpy(x_valid[start : start + batch_size]).permute(0, 3, 1, 2))\n",
    "    y = torch.from_numpy(np.argmax(y_valid[start : start + batch_size], axis=1))\n",
    "    outputs = cnn(x)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += y.size(0)\n",
    "    correct += (predicted == y).sum()\n",
    "    \n",
    "print('Test Accuracy of the model: %d %%' % (100 * correct / total))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
